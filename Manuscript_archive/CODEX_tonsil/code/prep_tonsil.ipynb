{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415f2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy\n",
    "import skimage\n",
    "# import custom functions\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "import utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from skimage.io import imread\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import regionprops\n",
    "from skimage.transform import resize\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import re\n",
    "import graph\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import regionprops\n",
    "from scipy.io import loadmat\n",
    "from skimage.io import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e8aa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102574, 55)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "load_path = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/data/tonsil/'\n",
    "metaload_path = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/data/tonsil/processed_data/meta_data/'\n",
    "df_clean = pd.read_csv(os.path.join(metaload_path , \"features_and_metadata.csv\"), index_col=0) # already cleaned\n",
    "xrange = [ 4, 5, 6, 7, 8]\n",
    "yrange = [8, 9, 10, 11, 12, 13]\n",
    "df_clean = df_clean[df_clean[\"X_view\"].isin(xrange) & df_clean[\"Y_view\"].isin(yrange)]\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca96bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/tonsil/data/'\n",
    "df = df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6703fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating cell neighborhood composition matrix...\n"
     ]
    }
   ],
   "source": [
    "# save out\n",
    "# feature edge\n",
    "# feature label\n",
    "# cell nbhd\n",
    "# spatial edge\n",
    "\n",
    "features_names = [\n",
    "        'HOECHST1', 'CD38', 'CD19', 'CD31',\n",
    "        'Vimentin', 'CD22', 'Ki67', 'CD8', 'CD90', 'CD123', 'CD15', 'CD3',\n",
    "        'CD152', 'CD21', 'cytokeratin', 'CD2', 'CD66', 'collagen IV', 'CD81',\n",
    "        'HLA-DR', 'CD57', 'CD4', 'CD7', 'CD278', 'podoplanin', 'CD45RA', 'CD34',\n",
    "        'CD54', 'CD9', 'IGM', 'CD117', 'CD56', 'CD279', 'CD45', 'CD49f', 'CD5',\n",
    "        'CD16', 'CD63', 'CD11b', 'CD1c', 'CD40', 'CD274', 'CD27', 'CD104',\n",
    "        'CD273', 'FAPalpha', 'Ecadherin'\n",
    "    ]\n",
    "features = df[features_names].to_numpy()\n",
    "features = utils.center_scale(features)\n",
    "\n",
    "res = 0.5\n",
    "knn = 20\n",
    "\n",
    "feature_edges = graph.get_feature_edges(\n",
    "    arr=features, pca_components=25,\n",
    "    n_neighbors=15, metric='correlation', verbose=False\n",
    ")\n",
    "\n",
    "feature_labels = graph.graph_clustering(\n",
    "    df.shape[0], feature_edges, resolution=res, n_clusters=None, n_runs=1,\n",
    "    resolution_tol=0.05, seed=None, verbose=False\n",
    ")\n",
    "\n",
    "np.save(os.path.join(data_dir, f'feature_labels_res{res}.npy'), feature_labels)\n",
    "np.save(os.path.join(data_dir, f'feature_edges_res{res}.npy'), np.array(feature_edges[:2]).T)\n",
    "\n",
    "print('Calculating cell neighborhood composition matrix...')\n",
    "locations = df[['centroid_x', 'centroid_y']].to_numpy()\n",
    "spatial_knn_indices = graph.get_spatial_knn_indices(locations=locations, n_neighbors=knn, method='kd_tree')\n",
    "cell_nbhd = utils.get_neighborhood_composition(knn_indices=spatial_knn_indices, labels=feature_labels)\n",
    "np.save(os.path.join(data_dir, f'cell_nbhd_res{res}_k{knn}.npy'), cell_nbhd)\n",
    "\n",
    "## save out spatial edge, always 15 cells\n",
    "locations = df[['centroid_x', 'centroid_y']].to_numpy()\n",
    "spatial_edges = graph.get_spatial_edges(\n",
    "    arr=locations, n_neighbors=15, verbose=True\n",
    ")\n",
    "np.save(os.path.join(data_dir, f'spatial_edges_0325.npy'), np.array(spatial_edges[:2]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20fd09f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(102574, 12), 12]\n"
     ]
    }
   ],
   "source": [
    "## just check dims\n",
    "\n",
    "print([cell_nbhd.shape, len(np.unique(feature_labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386a6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case need use\n",
    "np.save(os.path.join(data_dir, f'feature_scaled.npy'), features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d14fb2",
   "metadata": {},
   "source": [
    "Below is custom code to process CODEX tonsil images.\n",
    "\n",
    "First we need to again piece the seperated FOVs into the real tissue tile.\n",
    "\n",
    "Then produce cropped images out (save for CNN process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56118941",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom code written for this tonsil dataset, to piece images etc\n",
    "\n",
    "def save_train_test_data(df, size, load_path, save_folder, xrange,yrange, ratio, truncate = 3000, shape_of_each_view=(1008, 1344),\n",
    "                               channels = ('CD45', 'HOECHST1'), shape_of_views=(11, 9), pad = 500, verbose = True):\n",
    "    '''\n",
    "    For all cells in the dataframe, locate it in the picture and crop the image of given size, padding 0 if needed\n",
    "    Only select channels in the argument\n",
    "    Save numpy array of size n_cells * size * size * n_channels\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "    df is a pandas dataframe consisting of clean cells\n",
    "    '''\n",
    "    df[\"X_view\"] = df[\"PointNum\"].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "    df[\"Y_view\"] = df[\"PointNum\"].apply(lambda x: int(x.split('_')[2][1:]))\n",
    "    df = df[df[\"X_view\"].isin(xrange) & df[\"Y_view\"].isin(yrange)]\n",
    "    n_cell = df.shape[0]\n",
    "    print(f\"We have {n_cell} cells in total\")\n",
    "    n_channel = len(channels)\n",
    "    if verbose:\n",
    "        print(\"Combining all views...\", flush = True)\n",
    "    ### make all view into one big view\n",
    "\n",
    "    \n",
    "    all_folders = os.listdir(os.path.join(load_path, 'processed_raw_data/Images_singleChannel/'))\n",
    "    channels = ('CD45', 'HOECHST1')\n",
    "    pad_image = np.zeros((11*1008, 9*1344, 2))\n",
    "    for x in range(2, 11):\n",
    "        for y in range(5, 16):\n",
    "            # get folder name\n",
    "            x_str, y_str = ('0' + str(x))[-2:], ('0' + str(y))[-2:]\n",
    "            curr_folder = [name for name in all_folders if re.search('X' + x_str + '_Y' + y_str, name)]\n",
    "            assert len(curr_folder) == 1\n",
    "            curr_folder = curr_folder[0]\n",
    "            all_img_names = os.listdir(os.path.join(load_path, 'processed_raw_data/Images_singleChannel', curr_folder))\n",
    "            for channel_id, channel in enumerate(channels):\n",
    "                img_filename = [name for name in all_img_names if re.search(channel+'\\W', name)]\n",
    "                assert len(img_filename) == 1\n",
    "                img_filename = img_filename[0]\n",
    "                img = imread(\n",
    "                        os.path.join(\n",
    "                            load_path, 'processed_raw_data/Images_singleChannel', curr_folder, img_filename\n",
    "                        )\n",
    "                    )\n",
    "                pad_image[(y-5)*1008:(y-4)*1008, (x-2)*1344:(x-1)*1344, channel_id] = img\n",
    "    zero_pad_entire_view = np.zeros((pad_image.shape[0]+2*pad, pad_image.shape[1]+2*pad, pad_image.shape[2]))\n",
    "    zero_pad_entire_view[pad:pad_image.shape[0]+pad, pad:pad_image.shape[1]+pad, :] = pad_image\n",
    "\n",
    "#     zero_pad_entire_view[zero_pad_entire_view <= truncate] = 0\n",
    "#     zero_pad_entire_view[zero_pad_entire_view > truncate] = 1\n",
    "    if verbose:\n",
    "        print(\"Processing each cell...and saving!\", flush = True)\n",
    "    for i in tqdm(range(n_cell)):\n",
    "        # process each cell\n",
    "        center_x = df.iloc[i][\"centroid_x\"]\n",
    "        center_y = df.iloc[i][\"centroid_y\"]\n",
    "        temp_image = resize(zero_pad_entire_view[(int(center_x-size*ratio/2)+pad):(int(center_x+size*ratio/2)+pad), \n",
    "                                               (int(center_y-size*ratio/2)+pad):(int(center_y+size*ratio/2)+pad), \n",
    "                                               :], (size, size))\n",
    "        cur_image = np.zeros(temp_image.shape)\n",
    "        cur_image[temp_image > truncate] = 1\n",
    "        cur_image = np.transpose(cur_image, (2, 0, 1)).astype(np.int8)\n",
    "        \n",
    "        np.save(file = os.path.join(save_folder, f\"size{size}\", \"images\", f\"img_{i:06d}\"), arr = cur_image)\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = '../../../data/tonsil'\n",
    "df = df_clean\n",
    "xrange = [ 4, 5, 6, 7, 8]\n",
    "yrange = [8, 9, 10, 11, 12, 13]\n",
    "ratio = np.sqrt((53500/63)/(313338/99))\n",
    "\n",
    "save_folder = os.path.join(load_path, \"processed_data\", \"single_cell_images\")\n",
    "size = 512\n",
    "folder = os.path.join(save_folder, f\"size{size}\", \"images\")\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# truncate = 4000 is ~ quantile 0.9 in this dataset\n",
    "save_train_test_data(df, size, load_path, save_folder, xrange, yrange, ratio,truncate = 4000, shape_of_each_view=(1008, 1344),\n",
    "                              channels = ('CD45', 'HOECHST1'), shape_of_views=(11, 9), pad = 500, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
