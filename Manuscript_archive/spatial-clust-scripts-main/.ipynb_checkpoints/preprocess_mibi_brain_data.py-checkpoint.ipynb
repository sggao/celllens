{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skimage.measure import regionprops\n",
    "from scipy.io import loadmat\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "def get_cell_idx_partition(df):\n",
    "    \"\"\"\n",
    "    Return partition s.t. partition[i] = [start_i, end_i] are the\n",
    "    starting and ending indices (closed interval) in df for the i-th FOV (indexing from 1).\n",
    "    \"\"\"\n",
    "    starts = [0]\n",
    "    for i, curr_cell_idx in enumerate(df['cellLabelInImage']):\n",
    "        if i > 0 and curr_cell_idx < df['cellLabelInImage'].iloc[i - 1]:\n",
    "            starts.append(i)\n",
    "    partition = []\n",
    "    for i, s in enumerate(starts):\n",
    "        if i < len(starts) - 1:\n",
    "            partition.append([s, starts[i + 1] - 1])\n",
    "        else:\n",
    "            partition.append([s, df.shape[0] - 1])\n",
    "    return partition\n",
    "\n",
    "\n",
    "def add_cell_locations(\n",
    "        df, path_to_segmentation, shape_of_views=(2, 17), shape_of_each_view=(1024, 1024), verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Add three new columns to df: location coordinates (x, y) as well as which FOV is each cell in.\n",
    "    \"\"\"\n",
    "    # get the splitting points of different FOVs\n",
    "    partition = get_cell_idx_partition(df)\n",
    "    centroid_x = []\n",
    "    centroid_y = []\n",
    "    cell_views = []\n",
    "    \n",
    "    ind = 1\n",
    "    for view_j in range(shape_of_views[1]):\n",
    "        for view_i in range(shape_of_views[0]):\n",
    "            \n",
    "            if view_j > shape_of_views[1]:\n",
    "                ind = ind * -1\n",
    "            \n",
    "            view = view_j * shape_of_views[0] + view_i + 1\n",
    "            \n",
    "            if ind == 1:\n",
    "                topleft = [view_i * shape_of_each_view[0], view_j * shape_of_each_view[1]]\n",
    "            if ind == -1:\n",
    "                start = view_j * shape_of_each_view[1]\n",
    "                part1 = shape_of_each_view[1] * (shape_of_views[1] -1)\n",
    "                topleft = [view_i * shape_of_each_view[0], part1 - start]\n",
    "                    \n",
    "            if verbose:\n",
    "                print(\"Now at field of view {}, top-left coordinate is {}\".format(view, topleft), flush=True)\n",
    "            seg = scipy.io.loadmat(\n",
    "                '{}point{}/segmentationParams_obj.mat'.format(path_to_segmentation, view)\n",
    "            )['newLmod']\n",
    "            # get unique labels, excluding zero\n",
    "            unique_seg_labels = list(np.unique(seg.flatten()))[1:]\n",
    "            # calculate centroids\n",
    "            props = regionprops(seg)\n",
    "            # unique labels should align with props\n",
    "            assert len(unique_seg_labels) == len(props)\n",
    "            # build dict of seg_label: x and seg_label: y\n",
    "            seg_label_to_x = {}\n",
    "            seg_label_to_y = {}\n",
    "            for i in range(len(props)):\n",
    "                seg_label_to_x[unique_seg_labels[i]] = props[i]['centroid'][0] + topleft[0]\n",
    "                seg_label_to_y[unique_seg_labels[i]] = props[i]['centroid'][1] + topleft[1]\n",
    "            # fill the centroids of this segment of df\n",
    "            start, end = partition[view - 1]\n",
    "            for i in range(start, end + 1):\n",
    "                centroid_x.append(seg_label_to_x[df.iloc[i]['cellLabelInImage']])\n",
    "                centroid_y.append(seg_label_to_y[df.iloc[i]['cellLabelInImage']])\n",
    "                cell_views.append(view)\n",
    "    # add new columns\n",
    "    df['centroid_x'] = centroid_x\n",
    "    df['centroid_y'] = centroid_y\n",
    "    df['field_of_view'] = cell_views\n",
    "\n",
    "\n",
    "def pad_to_square(img):\n",
    "    \"\"\"\n",
    "    Pad the image to a square image.\n",
    "    \"\"\"\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    if h < w:\n",
    "        top_extra = (w - h) // 2\n",
    "        bottom_extra = w - h - top_extra\n",
    "        img = np.pad(img, [(top_extra, bottom_extra), (0, 0)])\n",
    "    elif h > w:\n",
    "        left_extra = (h - w) // 2\n",
    "        right_extra = h - w - left_extra\n",
    "        img = np.pad(img, [(0, 0), (left_extra, right_extra)])\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_each_cell(whole_image, segmentation, bounding_box, label_in_image, max_height, max_width, method='resize'):\n",
    "    \"\"\"\n",
    "    Given the whole image and the segmentation in a field of view,\n",
    "    extract a certain cell with label_in_image using bounding_box.\n",
    "    If method='resize', resize the image to shape (max_height, max_width),\n",
    "    if method='pad', pad the boundaries by zero so the image is of shape (max_height, max_width).\n",
    "    \"\"\"\n",
    "    # need to copy since we are setting some elements to zero\n",
    "    img_inside_box = whole_image[bounding_box[0]:bounding_box[2], bounding_box[1]:bounding_box[3]].copy()\n",
    "    seg_inside_box = segmentation[bounding_box[0]:bounding_box[2], bounding_box[1]:bounding_box[3]].copy()\n",
    "    for i in range(img_inside_box.shape[0]):\n",
    "        for j in range(img_inside_box.shape[1]):\n",
    "            if seg_inside_box[i, j] != label_in_image:\n",
    "                img_inside_box[i, j] = 0\n",
    "    if method == 'resize':\n",
    "        img_inside_box = pad_to_square(img_inside_box)\n",
    "        res = np.array(\n",
    "            resize(\n",
    "                img_inside_box, (max_height, max_width), preserve_range=True\n",
    "            )\n",
    "        )\n",
    "    elif method == 'pad':\n",
    "        h_extra_top = (max_height - img_inside_box.shape[0]) // 2\n",
    "        h_extra_bottom = max_height - h_extra_top - img_inside_box.shape[0]\n",
    "        w_extra_left = (max_width - img_inside_box.shape[1]) // 2\n",
    "        w_extra_right = max_width - w_extra_left - img_inside_box.shape[1]\n",
    "        res = np.pad(img_inside_box, [(h_extra_top, h_extra_bottom), (w_extra_left, w_extra_right)])\n",
    "        res = pad_to_square(res)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    return res\n",
    "\n",
    "\n",
    "def process_images(\n",
    "        df, load_path, channels=('HOECHST1', 'mem_CD45_Vim_HLA'),\n",
    "        method='resize', max_height=40, max_width=40, verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    First calculate the largest bounding box over all bounding boxes.\n",
    "    Then process the image of each cell if its cluster.term it not in ['empty', 'mix', dirt]:\n",
    "        - calculate its bounding box\n",
    "        - set the non-cell area to be zero\n",
    "        - if method='resize', resize the image to match the shape of (height, width)\n",
    "            if method='pad', pad it with zeros on the boundary to match the shape of the largest bounding box.\n",
    "    Save each cell as a numpy array in save_path/point=p_labels=l.npy\n",
    "        where p is the point of view and l is its label in image.\n",
    "    \"\"\"\n",
    "\n",
    "    partition = get_cell_idx_partition(df)\n",
    "    partition_iter = iter(partition)\n",
    "    all_folders = os.listdir(os.path.join(load_path, 'Images_singleChannel/'))\n",
    "\n",
    "    if method == 'pad':\n",
    "        # calculate largest bounding boxes\n",
    "        max_height = float('-inf')\n",
    "        max_width = float('-inf')\n",
    "        if verbose:\n",
    "            print(\"Calculating largest bounding boxes...\", flush=True)\n",
    "        for x in range(2, 11):\n",
    "            for y in range(5, 16):\n",
    "                if verbose:\n",
    "                    print(\"Now at ({}, {})...\".format(x, y), flush=True)\n",
    "                # get folder name\n",
    "                x_str, y_str = ('0' + str(x))[-2:], ('0' + str(y))[-2:]\n",
    "                curr_folder = [name for name in all_folders if re.search('X' + x_str + '_Y' + y_str, name)]\n",
    "                assert len(curr_folder) == 1\n",
    "                curr_folder = curr_folder[0]\n",
    "\n",
    "                # avoid bad cells\n",
    "                start, end = next(partition_iter)\n",
    "                good_cell_indices = set(\n",
    "                    [df['cellLabelInImage'].iloc[i] for i in range(start, end + 1)\n",
    "                     if df['cluster.term'].iloc[i] not in ['Other', 'mix']]\n",
    "                )\n",
    "\n",
    "                seg = scipy.io.loadmat(\n",
    "                    os.path.join(\n",
    "                        load_path, 'Images_singleChannel_0503seg',\n",
    "                        curr_folder, 'H3_CD45_Vim_HLA_Mesmer0111Whole_AutoHist_mpp0.6/segmentationParams.mat',\n",
    "                    )\n",
    "                )['newLmod']\n",
    "\n",
    "                # get unique labels, excluding zero\n",
    "                unique_seg_labels = list(np.unique(seg.flatten()))[1:]\n",
    "                # calculate bounding boxes\n",
    "                props = regionprops(seg)\n",
    "                # unique labels should align with props\n",
    "                assert len(unique_seg_labels) == len(props)\n",
    "                for i in range(len(props)):\n",
    "                    if unique_seg_labels[i] not in good_cell_indices:\n",
    "                        continue\n",
    "                    bounding_box = props[i]['BoundingBox']\n",
    "                    max_height = max(max_height, bounding_box[2] - bounding_box[0])\n",
    "                    max_width = max(max_width, bounding_box[3] - bounding_box[1])\n",
    "        if verbose:\n",
    "            print('max_height={}, max_width={}'.format(max_height, max_width))\n",
    "\n",
    "    if verbose:\n",
    "        print('Processing images...', flush=True)\n",
    "\n",
    "    # process images\n",
    "    partition_iter = iter(partition)\n",
    "    res = [[] for _ in channels]\n",
    "    for x in range(2, 11):\n",
    "        for y in range(5, 16):\n",
    "            # get folder name\n",
    "            x_str, y_str = ('0' + str(x))[-2:], ('0' + str(y))[-2:]\n",
    "            curr_folder = [name for name in all_folders if re.search('X' + x_str + '_Y' + y_str, name)]\n",
    "            assert len(curr_folder) == 1\n",
    "            curr_folder = curr_folder[0]\n",
    "\n",
    "            # avoid bad cells\n",
    "            start, end = next(partition_iter)\n",
    "            good_cell_indices = set(\n",
    "                [df['cellLabelInImage'].iloc[i] for i in range(start, end + 1)\n",
    "                 if df['cluster.term'].iloc[i] not in ['Other', 'mix']]\n",
    "            )\n",
    "            if verbose:\n",
    "                print(\"Now at ({}, {})...\".format(x, y), flush=True)\n",
    "\n",
    "            seg = scipy.io.loadmat(\n",
    "                os.path.join(\n",
    "                    load_path, 'Images_singleChannel_0503seg',\n",
    "                    curr_folder, 'H3_CD45_Vim_HLA_Mesmer0111Whole_AutoHist_mpp0.6/segmentationParams.mat',\n",
    "                )\n",
    "            )['newLmod']\n",
    "\n",
    "            # get unique labels, excluding zero\n",
    "            unique_seg_labels = list(np.unique(seg.flatten()))[1:]\n",
    "            # calculate bounding boxes\n",
    "            props = regionprops(seg)\n",
    "\n",
    "            all_img_names = os.listdir(os.path.join(load_path, 'Images_singleChannel', curr_folder))\n",
    "            for channel_id, channel in enumerate(channels):\n",
    "                img_filename = [name for name in all_img_names if re.search(channel+'\\W', name)]\n",
    "                assert len(img_filename) == 1\n",
    "                img_filename = img_filename[0]\n",
    "                img = imread(\n",
    "                    os.path.join(\n",
    "                        load_path, 'Images_singleChannel', curr_folder, img_filename\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for i in range(len(props)):\n",
    "                    if unique_seg_labels[i] not in good_cell_indices:\n",
    "                        continue\n",
    "                    each_img = process_each_cell(\n",
    "                        whole_image=img,\n",
    "                        segmentation=seg,\n",
    "                        bounding_box=props[i]['BoundingBox'],\n",
    "                        label_in_image=unique_seg_labels[i],\n",
    "                        max_height=max_height,\n",
    "                        max_width=max_width,\n",
    "                        method=method\n",
    "                    )\n",
    "                    res[channel_id].append(each_img)\n",
    "\n",
    "    res = np.array(res)\n",
    "    res = np.transpose(res, (1, 0, 2, 3))\n",
    "    return res\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # read in raw feature data\n",
    "    print('Reading in the data...')\n",
    "    df_raw = pd.read_csv('../data/tonsil/processed_raw_data/all_clusters.csv', index_col=0)\n",
    "    # clean dirty cells\n",
    "    df_clean = df_raw.iloc[\n",
    "        [i for i, label in enumerate(df_raw['cluster.term']) if label not in ['Other', 'mix']]\n",
    "    ]\n",
    "    # clean unused columns\n",
    "    df_clean = df_clean.drop(['PointNum', 'seurat_res1.0'], axis=1)\n",
    "\n",
    "    print('The cleaned dataframe contain columns: {}'.format(list(df_clean.columns)))\n",
    "\n",
    "    # add spatial coordinates (centroid_x, centroid_y) and the field_of_view for each cell\n",
    "    print('Filling in spatial information...')\n",
    "    add_cell_locations(\n",
    "        df=df_clean,\n",
    "        path_to_segmentation='../data/tonsil/processed_raw_data/Images_singleChannel_0503seg/',\n",
    "        shape_of_each_view=(1008, 1344), verbose=True)\n",
    "\n",
    "    df_clean.to_csv('../data/tonsil/processed_data/features_and_metadata.csv')\n",
    "\n",
    "    df_clean.iloc[:50000, :].to_csv('../data/tonsil/processed_data/50k_features_and_metadata.csv')\n",
    "\n",
    "    # # process single-cell level images\n",
    "    print('Processing single-cell images...')\n",
    "    processed_images = process_images(\n",
    "        df=df_raw, load_path='../data/tonsil/processed_raw_data',\n",
    "        channels=('HOECHST1', 'mem_CD45_Vim_HLA'),\n",
    "        method='pad', max_height=None, max_width=None,\n",
    "        verbose=True\n",
    "    )\n",
    "    np.save(file='../data/tonsil/processed_data/images_pad.npy', arr=processed_images)\n",
    "    np.save(file='../data/tonsil/processed_data/50k_images_pad.npy', arr=processed_images[:50000])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
