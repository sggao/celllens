{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb916ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "from torchvision import transforms\n",
    "import graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy\n",
    "import skimage\n",
    "# import custom functions\n",
    "import sys\n",
    "import utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c28475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_cell512_channel2(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 16, kernel_size = 2, stride = 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 3, stride = 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 4, stride = 2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size = 2, stride = 1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size = 2, stride = 1)\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size = 2, stride = 1)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, size)\n",
    "    \n",
    "    def cnn_encoder(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_encoder(x)\n",
    "        x = self.fc4(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfe9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCellImageDataset_Stream(Dataset):\n",
    "    def __init__(self, img_path, train_mask, cell_nbhd, use_transform):\n",
    "        \"\"\"\n",
    "        Form dataset of single cells\n",
    "        Parameters\n",
    "        ----------\n",
    "        images: np.ndarray of shape (n_samples, C, H, W)\n",
    "        cell_nbhd: np.ndarray of shape (n_samples, d)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomRotation(degrees=180),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip()\n",
    "        ])\n",
    "        self.labels = cell_nbhd\n",
    "        self.use_transform = use_transform\n",
    "        self.img_path = img_path\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         if self.use_transform:\n",
    "#             ind = self.train_list[index]\n",
    "#         else:\n",
    "#             ind = self.test_list[index]\n",
    "        img = np.load(os.path.join(self.img_path, f\"img_{index:05d}.npy\"))\n",
    "        if self.use_transform:\n",
    "            img = self.transform(torch.Tensor(img))\n",
    "        labels = self.labels[index]\n",
    "        return img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb7ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bokai \n",
    "metaload_path = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/spleen/data/'\n",
    "# sheng other meta\n",
    "metaload_path2 = '../../../../../data/codex_murine/processed_data' # only for images etc\n",
    "\n",
    "df_clean = pd.read_csv(os.path.join(metaload_path,  \"features_and_metadata.csv\"), index_col=0)\n",
    "cell_nbhd = np.load(os.path.join(metaload_path,  \"cell_nbhd_res0.5_k20_0325.npy\"))\n",
    "train_mask = np.load(os.path.join(metaload_path2, \"meta_data\", \"train_mask.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9657177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(53500, 15), (53500,), (53500, 39)]\n"
     ]
    }
   ],
   "source": [
    "print([cell_nbhd.shape, train_mask.shape, df_clean.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75adc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 512\n",
    "\n",
    "load_path = '../../../../../data/codex_murine/' # this is images produced by sheng?\n",
    "image_folder = os.path.join(load_path, \"processed_data\", \"single_cell_images\", f\"size{size}\")\n",
    "dataset = SingleCellImageDataset_Stream(os.path.join(image_folder, \"images\"), None, cell_nbhd, use_transform = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc3c7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 512\n",
    "testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87d8635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:34<00:00, 23.72s/it]\n"
     ]
    }
   ],
   "source": [
    "l = 1\n",
    "for a in [512]:\n",
    "    \n",
    "    model_save_path = os.path.join(metaload_path, \"cnn_0325\", 'cnn_512_l1_layer6' ,\"epochs\")\n",
    "    size = cell_nbhd.shape[1]\n",
    "    cnn_net = CNN_cell512_channel2(size)\n",
    "        \n",
    "    cnn_net = cnn_net.to(device)\n",
    "    for epoch in tqdm([100, 200, 300, 400]):\n",
    "        cnn_net.load_state_dict(torch.load(os.path.join(model_save_path, f\"epoch{epoch}_model_weights.pth\")))\n",
    "        data_size = cell_nbhd.shape[0]\n",
    "        cnn_embedding = np.zeros((data_size, 128))\n",
    "\n",
    "        start_idx = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device).to(torch.float32)\n",
    "                outputs = cnn_net.cnn_encoder(inputs)\n",
    "                cnn_embedding[start_idx: start_idx + inputs.shape[0]] = outputs.cpu()\n",
    "\n",
    "                start_idx += inputs.shape[0]\n",
    "        assert(start_idx == data_size)\n",
    "        save_folder = os.path.join(model_save_path, 'embed', f\"cnn_{a}_notrans_l{l}_layer6_byepoch\")\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "        np.save(os.path.join(save_folder, f\"cnn_embedding_{a}_full_l{l}_dim128_epoch{epoch}.npy\"), cnn_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
