{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bb845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "sys.path.append(\"../../../../../\")\n",
    "\n",
    "from torchvision import transforms\n",
    "import graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy\n",
    "import skimage\n",
    "# import custom functions\n",
    "import sys\n",
    "import utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f3bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_cell512_channel2(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 16, kernel_size = 2, stride = 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 3, stride = 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 4, stride = 2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size = 2, stride = 1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size = 2, stride = 1)\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size = 2, stride = 1)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, size)\n",
    "    \n",
    "    def cnn_encoder(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_encoder(x)\n",
    "        x = self.fc4(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1657370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCellImageDataset_Stream(Dataset):\n",
    "    def __init__(self, img_path, train_mask, cell_nbhd, use_transform):\n",
    "        \"\"\"\n",
    "        Form dataset of single cells\n",
    "        Parameters\n",
    "        ----------\n",
    "        images: np.ndarray of shape (n_samples, C, H, W)\n",
    "        cell_nbhd: np.ndarray of shape (n_samples, d)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomRotation(degrees=180),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip()\n",
    "        ])\n",
    "        self.labels = cell_nbhd\n",
    "        self.use_transform = use_transform\n",
    "        self.img_path = img_path\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         if self.use_transform:\n",
    "#             ind = self.train_list[index]\n",
    "#         else:\n",
    "#             ind = self.test_list[index]\n",
    "        img = np.load(os.path.join(self.img_path, f\"img_{index:05d}.npy\"))\n",
    "        if self.use_transform:\n",
    "            img = self.transform(torch.Tensor(img))\n",
    "        labels = self.labels[index]\n",
    "        return img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d86e4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/benchmark/spleen/data/'\n",
    "#df_clean = pd.read_csv(os.path.join(load_path, \"\"), index_col=0)\n",
    "cell_nbhd = np.load(os.path.join(load_path, \"cell_nbhd_res0.5_k20.npy\")) # default\n",
    "train_mask = np.load(os.path.join(load_path, \"train_mask.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb272203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(53500, 17), (53500,)]\n"
     ]
    }
   ],
   "source": [
    "print([cell_nbhd.shape, train_mask.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55ad0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path2 = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/data/codex_murine/'\n",
    "\n",
    "#alpha = 0.6 \n",
    "#alpha = 0.7 \n",
    "#alpha = 0.8 \n",
    "alpha = 0.9\n",
    "\n",
    "size = 512 # default\n",
    "\n",
    "train_nbhd = cell_nbhd[train_mask, :]\n",
    "test_nbhd = cell_nbhd[~train_mask, :]\n",
    "\n",
    "image_folder = os.path.join(load_path2, \"processed_data\", \"single_cell_images\", f\"size{size}_qr{alpha}\")\n",
    "dataset = SingleCellImageDataset_Stream(os.path.join(image_folder,\"images\"),\n",
    "                                        None, cell_nbhd, use_transform = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3972a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 512\n",
    "testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6efb96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 4/4 [01:24<00:00, 21.06s/it]\n"
     ]
    }
   ],
   "source": [
    "l = 1\n",
    "for a in [512]:\n",
    "    \n",
    "    model_save_path = os.path.join(load_path, \"cnn\", f\"cnn_512_l{l}_layer6_testalpha:0.9_checkpoints\", \"epochs\")\n",
    "    size = cell_nbhd.shape[1]\n",
    "    cnn_net = CNN_cell512_channel2(size)\n",
    "        \n",
    "    cnn_net = cnn_net.to(device)\n",
    "    for epoch in tqdm([100, 200, 300, 400]):\n",
    "        cnn_net.load_state_dict(torch.load(os.path.join(model_save_path, f\"epoch{epoch}_model_weights.pth\")))\n",
    "        data_size = cell_nbhd.shape[0]\n",
    "        cnn_embedding = np.zeros((data_size, 128))\n",
    "\n",
    "        start_idx = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device).to(torch.float32)\n",
    "                outputs = cnn_net.cnn_encoder(inputs)\n",
    "                cnn_embedding[start_idx: start_idx + inputs.shape[0]] = outputs.cpu()\n",
    "\n",
    "                start_idx += inputs.shape[0]\n",
    "        assert(start_idx == data_size)\n",
    "        save_folder = os.path.join(model_save_path, 'embed', f\"cnn_{a}_testalpha:0.9_l{l}_layer6_byepoch\")\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "        np.save(os.path.join(save_folder, f\"cnn_embedding_{a}_full_l{l}_dim128_epoch{epoch}.npy\"), cnn_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c95045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
